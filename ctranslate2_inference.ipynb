{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers sentencepiece torch ctranslate2 -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "hf_hub_download(repo_id='anzorq/m2m100_418M_ft_ru-kbd_44K', subfolder='ctranslate2', filename='config.json', local_dir='./')\n",
    "hf_hub_download(repo_id='anzorq/m2m100_418M_ft_ru-kbd_44K', subfolder='ctranslate2', filename='model.bin', local_dir='./')\n",
    "hf_hub_download(repo_id='anzorq/m2m100_418M_ft_ru-kbd_44K', subfolder='ctranslate2', filename='sentencepiece.bpe.model', local_dir='./')\n",
    "hf_hub_download(repo_id='anzorq/m2m100_418M_ft_ru-kbd_44K', subfolder='ctranslate2', filename='shared_vocabulary.json', local_dir='./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctranslate2\n",
    "import transformers\n",
    "\n",
    "translator = ctranslate2.Translator(\"ctranslate2\") # Ensure correct path to the ctranslate2 model directory\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"anzorq/m2m100_418M_ft_ru-kbd_44K\")\n",
    "tgt_lang=\"zu\"\n",
    "\n",
    "def translate(text, num_beams=4, num_return_sequences=4):\n",
    "    num_return_sequences = min(num_return_sequences, num_beams)\n",
    "\n",
    "    source = tokenizer.convert_ids_to_tokens(tokenizer.encode(text))\n",
    "    target_prefix = [tokenizer.lang_code_to_token[tgt_lang]]\n",
    "    results = translator.translate_batch(\n",
    "        [source],\n",
    "        target_prefix=[target_prefix],\n",
    "        beam_size=num_beams,\n",
    "        num_hypotheses=num_return_sequences\n",
    "    )\n",
    "    \n",
    "    translations = []\n",
    "    for hypothesis in results[0].hypotheses:\n",
    "        target = hypothesis[1:]\n",
    "        decoded_sentence = tokenizer.decode(tokenizer.convert_tokens_to_ids(target))\n",
    "        translations.append(decoded_sentence)\n",
    "    \n",
    "    return text, translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Translation\n",
    "\n",
    "text = \"Текст для перевода\" #@param {type: \"string\"}\n",
    "num_beams = 4 # @param {type:\"slider\", min:2, max:10, step:1}\n",
    "print(translate(text))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
